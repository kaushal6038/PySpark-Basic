{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *  # Necessary for creating schemas\n",
    "from pyspark.sql.functions import * # Importing PySpark functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames\n",
    "### Making a Simple DataFrame from a Tuple List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a tuple list\n",
    "a_list = [('a', 1), ('b', 2), ('c', 3)]\n",
    "\n",
    "# Create a Spark DataFrame, without supplying a schema value\n",
    "df_from_list_no_schema = \\\n",
    "sqlContext.createDataFrame(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_list_no_schema.registerTempTable(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='data', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st O/P : DataFrame[_1: string, _2: bigint] \n",
      "\n",
      "2nd O/P : [Row(_1='a', _2=1), Row(_1='b', _2=2), Row(_1='c', _2=3)] \n",
      "\n",
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "|  a|  1|\n",
      "|  b|  2|\n",
      "|  c|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the DataFrame\n",
    "print(\"1st O/P : %s \\n\" % df_from_list_no_schema )\n",
    "print(\"2nd O/P : %s \\n\" %df_from_list_no_schema.collect())\n",
    "df_from_list_no_schema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Simple DataFrame from a Tuple List and a Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark DataFrame, this time with schema\n",
    "df_from_list_with_schema = \\\n",
    "sqlContext.createDataFrame(a_list, ['letters', 'numbers']) # this simple schema contains just column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n",
      "root\n",
      " |-- letters: string (nullable = true)\n",
      " |-- numbers: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the DataFrame\n",
    "df_from_list_with_schema.show()\n",
    "\n",
    "# Show the DataFrame's schema\n",
    "df_from_list_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Simple DataFrame from a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary\n",
    "a_dict = [{'letters': 'a', 'numbers': 1},\n",
    "          {'letters': 'b', 'numbers': 2},\n",
    "          {'letters': 'c', 'numbers': 3}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('letters', 'string'), ('numbers', 'bigint')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Spark DataFrame from the dictionary\n",
    "df_from_dict = sqlContext.createDataFrame(a_dict) # You will get a warning about this\n",
    "\n",
    "# Show the DataFrame\n",
    "df_from_dict.show()\n",
    "\n",
    "# Data types \n",
    "df_from_dict.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Simple DataFrame Using a StructType Schema + RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField('letters', StringType(), True),\n",
    "    StructField('numbers', IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD from a list\n",
    "rdd = sc.parallelize(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame from these raw components\n",
    "nice_df = sqlContext.createDataFrame(rdd, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some functions for inspecting the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['letters', 'numbers']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `columns`: return all column names as a list\n",
    "nice_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('letters', 'string'), ('numbers', 'int')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `dtypes`: get the datatypes for all columns\n",
    "nice_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- letters: string (nullable = true)\n",
      " |-- numbers: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# `printSchema()`: prints the schema of the supplied DF\n",
    "nice_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(letters,StringType,true),StructField(numbers,IntegerType,true)))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `schema`: returns the schema of the provided DF as `StructType` schema\n",
    "nice_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(letters='a', numbers=1)\n",
      "[Row(letters='a', numbers=1), Row(letters='b', numbers=2), Row(letters='c', numbers=3)]\n",
      "[Row(letters='a', numbers=1), Row(letters='b', numbers=2), Row(letters='c', numbers=3)]\n"
     ]
    }
   ],
   "source": [
    "# `first()` returns the first row as a Row while\n",
    "print(nice_df.first()) # can't supply a value; never a list\n",
    "\n",
    "print(nice_df.head(4)) # can optionally supply a value (default: 1);\n",
    "                       # with n > 1, a list\n",
    "\n",
    "print(nice_df.take(4)) # always expects a value; always a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `count()`: returns a count of all rows in DF\n",
    "nice_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|summary|letters|numbers|\n",
      "+-------+-------+-------+\n",
      "|  count|      3|      3|\n",
      "|   mean|   null|    2.0|\n",
      "| stddev|   null|    1.0|\n",
      "|    min|      a|      1|\n",
      "|    max|      c|      3|\n",
      "+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# `describe()`: print out stats for numerical columns\n",
    "nice_df.describe().show() # can optionally supply a list of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Scan ExistingRDD[letters#145,numbers#146]\n"
     ]
    }
   ],
   "source": [
    "# the `explain()` function explains the under-the-hood evaluation process\n",
    "nice_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple DataFrame Manipulation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  unionAll(): combine two DataFrames together\n",
    "###  orderBy(): perform sorting of DataFrame columns\n",
    "###  select(): select which DataFrame columns to retain\n",
    "###  drop(): select a single DataFrame column to remove\n",
    "###  filter(): retain DataFrame rows that match a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take the DataFrame and add it to itself\n",
    "(df_from_dict.unionAll(nice_df).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add it to itself twice\n",
    "(df_from_dict.unionAll(nice_df).unionAll(df_from_list_no_schema).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|numbers|letters|\n",
      "+-------+-------+\n",
      "|      1|      a|\n",
      "|      2|      b|\n",
      "|      3|      c|\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n",
      "root\n",
      " |-- numbers: string (nullable = true)\n",
      " |-- letters: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Coercion will occur if schemas don't align\n",
    "(nice_df.select(['numbers', 'letters']).unionAll(nice_df).show())\n",
    "\n",
    "(nice_df.select(['numbers', 'letters']).unionAll(nice_df).printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      a|      1|\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "|      b|      2|\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "|      c|      3|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting the DataFrame by the `numbers` column\n",
    "(nice_df\n",
    " .unionAll(nice_df)\n",
    " .unionAll(nice_df)\n",
    " .orderBy(\"numbers\")\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      c|      3|\n",
      "|      c|      3|\n",
      "|      c|      3|\n",
      "|      b|      2|\n",
      "|      b|      2|\n",
      "|      b|      2|\n",
      "|      a|      1|\n",
      "|      a|      1|\n",
      "|      a|      1|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the same column in reverse order\n",
    "(nice_df\n",
    " .unionAll(nice_df)\n",
    " .unionAll(nice_df)\n",
    " .orderBy('numbers',\n",
    "          ascending = False)\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|letters|\n",
      "+-------+\n",
      "|      a|\n",
      "|      b|\n",
      "|      c|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# `select()` and `drop()` both take a list of column names\n",
    "# Select only the desired columns of the DF\n",
    "(nice_df\n",
    " .select('letters')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|numbers|letters|\n",
      "+-------+-------+\n",
      "|      1|      a|\n",
      "|      2|      b|\n",
      "|      3|      c|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-order columns in the DF using `select()`\n",
    "(nice_df\n",
    " .select(['numbers', 'letters'])\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|numbers|\n",
      "+-------+\n",
      "|      1|\n",
      "|      2|\n",
      "|      3|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop the second column of the DF\n",
    "(nice_df\n",
    " .drop('letters')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      b|      2|\n",
      "|      c|      3|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The `filter()` function performs filtering of DF rows\n",
    "\n",
    "# Here is some numeric filtering with comparison operators\n",
    "# (>, <, >=, <=, ==, != all work)\n",
    "\n",
    "# Filter rows where values in `numbers` is > 1\n",
    "(nice_df\n",
    " .filter(nice_df.numbers > 1)\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      b|      2|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing two filter operations\n",
    "(nice_df\n",
    " .filter(nice_df.numbers > 1)\n",
    " .filter(nice_df.numbers < 3)\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|letters|numbers|\n",
      "+-------+-------+\n",
      "|      a|      1|\n",
      "|      b|      2|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Not just numbers! Use the `filter()` + `isin()`\n",
    "# combo to filter on string columns with a set of values\n",
    "(nice_df\n",
    " .filter(nice_df.letters\n",
    "         .isin(['a', 'b']))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schema object...\n",
    "nycflights_schema = StructType([\n",
    "  StructField('year', IntegerType(), True),\n",
    "  StructField('month', IntegerType(), True),\n",
    "  StructField('day', IntegerType(), True),\n",
    "  StructField('dep_time', StringType(), True),\n",
    "  StructField('dep_delay', IntegerType(), True),\n",
    "  StructField('arr_time', StringType(), True),\n",
    "  StructField('arr_delay', IntegerType(), True),\n",
    "  StructField('carrier', StringType(), True),\n",
    "  StructField('tailnum', StringType(), True),\n",
    "  StructField('flight', StringType(), True),  \n",
    "  StructField('origin', StringType(), True),\n",
    "  StructField('dest', StringType(), True),\n",
    "  StructField('air_time', IntegerType(), True),\n",
    "  StructField('distance', IntegerType(), True),\n",
    "  StructField('hour', IntegerType(), True),\n",
    "  StructField('minute', IntegerType(), True)\n",
    "  ])\n",
    "\n",
    "# ...and then read the CSV with the schema\n",
    "nycflights = \\\n",
    "(sqlContext\n",
    " .read\n",
    " .format('com.databricks.spark.csv')\n",
    " .schema(nycflights_schema)\n",
    " .options(header = True)\n",
    " .load('nycflights13.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
